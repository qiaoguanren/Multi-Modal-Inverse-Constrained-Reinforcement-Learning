task: 'MEICRL-highD-distance'
group: 'MEICRL'
device: 'cuda'
verbose: 1
env:
  config_path: "../config/highD_distance_constraint/highD_environment_configurations_no_slo_distance_penalty_dm-20.yaml"
  train_env_id : 'commonroad-v1'
  eval_env_id: 'commonroad-v1'
  save_dir: '../save_model'
  constraint_id: null
  cost_info_str: 'cost'
  latent_info_str: 'latent'
  use_cost: True
  reward_gamma: 0.99
  cost_gamma: 0.99
  dont_normalize_obs: False
  dont_normalize_reward: False
  dont_normalize_cost: False  # no cost
  record_info_names: ["same_lane_leading_obstacle_distance"]
  record_info_input_dims: [22] # the dim of record info in inputs=(obs, action)
  visualize_info_ranges: [[ 0, 100] ]

running:
  n_iters: 500
  n_eval_episodes: 10
  save_every: 50
  max_seq_length: 10
  expert_rollouts: 100
  sample_rollouts: 100
  store_sample_rollouts: null
  expert_path: '../data/expert_data/Mixture-HighDDistanceConstraint/'
  use_buffer: False
  store_by_game: True
  init_density: False

PPO:
  policy_name: 'TwoCriticsMlpPolicy'
  learning_rate: 0.0005 # 0.0003
  n_steps: 1024 #2048
  n_epochs: 10
  clip_obs: 20
  reward_gamma: 0.99
  reward_gae_lambda: 0.95
  cost_gamma: 0.99
  cost_gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  reward_vf_coef: 0.5
  cost_vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: False
  sde_sample_freq: -1
  target_kl: 0.01
  shared_layers: null
  policy_layers: [64, 64]
  reward_vf_layers: [64, 64]
  cost_vf_layers: [64, 64]
  batch_size: null
  eval_every: 2048
  use_curiosity_driven_exploration: False
  warmup_timesteps: False
  reset_policy: False
  forward_timesteps: 5000
  clip_range_reward_vf: null
  clip_range_cost_vf: null
  penalty_initial_value: 10
  penalty_learning_rate: 0.01
  budget: 0
  proportional_control_coeff: 10
  integral_control_coeff: 0.0001
  derivative_control_coeff: 0
  pid_delay: 1
  proportional_cost_ema_alpha: 0.5
  derivative_cost_ema_alpha: 0.5
  log_cost: True
  contrastive_augment_type: 'reward augmentation'

CN:
  cn_learning_rate: 0.0005
  density_learning_rate: 0.0005
  cn_reg_coeff: 0.5
  cn_layers: [64, 64, 64]
  cn_batch_size: 64
  cn_obs_select_name: ['lane_based_p_rel_0', 'lane_based_p_rel_1', 'lane_based_p_rel_2', 'lane_based_p_rel_3', 'lane_based_p_rel_4', 'lane_based_p_rel_5']
  cn_acs_select_name: null # null means all
  no_importance_sampling: True
  per_step_importance_sampling: False
  clip_obs: 1000
  cn_normalize: True
  cn_target_kl_old_new: 10
  cn_target_kl_new_old: 2.5
  train_gail_lambda: False
  cn_eps: 0.00001
  backward_iters: 50
  anneal_clr_by_factor: 0.9
  latent_dim: 2
  use_expert_negative: True
  negative_weight: 0.5
  sample_probing_points: False
  n_probings: 10
  reverse_probing: False
  contrastive_weight: 0.5
  recon_obs: False